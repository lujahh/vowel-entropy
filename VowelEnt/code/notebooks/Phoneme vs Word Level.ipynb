{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import collections, functools, operator \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file to list of lists\n",
    "#0: orthography\n",
    "#1: phon w/o r dipthong char\n",
    "#2: freq 1\n",
    "#3: freq 2\n",
    "#4: phon w/ r dipthong char\n",
    "r1 = []\n",
    "myFile= open( \"CMUDict_Lemma_RDip_SubtlexFreqs.txt\", \"r\" )\n",
    "for aRow in myFile:\n",
    "    r1.append(aRow.strip('\\n').split('\\t'))\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the number of each character in each word, multiplied by the frequency for that word\n",
    "list_of_dict = []\n",
    "for ii in range(0, len(r1)):\n",
    "    local_dict = dict(Counter(r1[ii][4]))\n",
    "    #multiply by freq\n",
    "    for key in local_dict:\n",
    "        local_dict[key] *= float(r1[ii][3])\n",
    "    list_of_dict.append(local_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum everything together to get the counts for each character in the corpus based on word frequency\n",
    "result = dict(functools.reduce(operator.add, \n",
    "         map(collections.Counter, list_of_dict))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just the monopthongy vowels\n",
    "vowels = { 'i', 'I', 'e', 'E', '@', 'u', 'U', 'o', 'c', 'a', 'V', 'R' }\n",
    "vowels_token = { key:value for key,value in result.items() if key in vowels}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of vowel system (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowels_token.values())\n",
    "\n",
    "#now divide the frequency of each vowel by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowels_token:\n",
    "    probabilities[key] = vowels_token[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowels_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3878689259664196"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowels_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contribution of vowels to the system (token freq)\n",
    "\n",
    "#entropy of the entire system first\n",
    "totalfreq = sum(result.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in result:\n",
    "    probabilities[key] = result[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_total = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0571104380771805"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system without vowels\n",
    "nonvowel = { key:value for key,value in result.items() if not key in vowels}\n",
    "\n",
    "\n",
    "totalfreq = sum(nonvowel.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in nonvowel:\n",
    "    probabilities[key] = nonvowel[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_nonvowel = sum(surprisals.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.513860441153023"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_nonvowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels_same_freq= sum(vowels_token.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "onevowel = {**nonvowel, **{'V': vowels_same_freq}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system with all vowels merged\n",
    "totalfreq = sum(onevowel.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in onevowel:\n",
    "    probabilities[key] = onevowel[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_onevowel = sum(surprisals.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0486482461618625"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_onevowel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_contr = (entropy_total - entropy_onevowel)/ entropy_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19941470613775178"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## front vs. back vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum all frequencies of front vowels & sum all frequencies of back vowels. \n",
    "frontvowels = { 'i', 'I', 'e', 'E', '@', 'R' }\n",
    "frontvowels_dict = { key:value for key,value in result.items() if key in frontvowels}\n",
    "frontvowels_freq = sum(frontvowels_dict.values())\n",
    "\n",
    "backvowels = { 'u', 'U', 'o', 'c', 'a', 'V' }\n",
    "backvowels_dict = { key:value for key,value in result.items() if key in backvowels}\n",
    "backvowels_freq = sum(backvowels_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of phonemes with all front vowels merged and all back vowels merged - choose i for front and u for back\n",
    "frontback = {**nonvowel, **{'i':frontvowels_freq}, **{'u':backvowels_freq}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system with all vowels merged\n",
    "totalfreq = sum(frontback.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in frontback:\n",
    "    probabilities[key] = frontback[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_frontback = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.340159974134184"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_frontback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1417707745800379"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_contr = (entropy_total - entropy_frontback)/ entropy_total\n",
    "vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## high vs. low vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum all frequencies of high vowels & sum all frequencies of low vowels. \n",
    "highvowels = { 'i', 'I', 'e', 'u', 'U', 'o' }\n",
    "highvowels_dict = { key:value for key,value in result.items() if key in highvowels}\n",
    "highvowels_freq = sum(highvowels_dict.values())\n",
    "\n",
    "lowvowels = { 'E', '@', 'R', 'c', 'a', 'V' }\n",
    "lowvowels_dict = { key:value for key,value in result.items() if key in lowvowels}\n",
    "lowvowels_freq = sum(lowvowels_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of phonemes with all high vowels merged and all low vowels merged\n",
    "#choose i for high and E for low\n",
    "highlow = {**nonvowel, **{'i':highvowels_freq}, **{'E':lowvowels_freq}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system with all vowels merged\n",
    "totalfreq = sum(highlow.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in highlow:\n",
    "    probabilities[key] = highlow[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_highlow = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.346237739804603"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_highlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1405689488052522"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_contr = (entropy_total - entropy_highlow)/ entropy_total\n",
    "vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tense vs. lax vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum all frequencies of tense vowels & sum all frequencies of lax vowels. \n",
    "tensevowels = { 'i', 'e', 'u', 'a', 'o', 'c' }\n",
    "tensevowels_dict = { key:value for key,value in result.items() if key in tensevowels}\n",
    "tensevowels_freq = sum(tensevowels_dict.values())\n",
    "\n",
    "laxvowels = { 'I', 'E', '@', 'R', 'U', 'V' }\n",
    "laxvowels_dict = { key:value for key,value in result.items() if key in laxvowels}\n",
    "laxvowels_freq = sum(laxvowels_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of phonemes with all tense vowels merged and all lax vowels merged\n",
    "#choose i for tense and I for lax\n",
    "tenselax = {**nonvowel, **{'i':tensevowels_freq}, **{'I':laxvowels_freq}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system with all vowels merged\n",
    "totalfreq = sum(tenselax.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in tenselax:\n",
    "    probabilities[key] = tenselax[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_tenselax = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.345566678837873"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_tenselax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14070164532729712"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_contr = (entropy_total - entropy_tenselax)/ entropy_total\n",
    "vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now look at specific vowel mergers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0333389713024514"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a c merger\n",
    "vowelstomerge = {'a', 'c'}\n",
    "vowelstomerge_dict = { key:value for key,value in result.items() if key in vowelstomerge}\n",
    "vowelstomerge_freq = sum(vowelstomerge_dict.values())\n",
    "nonmerged_dict = { key:value for key,value in result.items() if not key in vowelstomerge}\n",
    "merged = {**nonmerged_dict, **{'<':vowelstomerge_freq}} #using < to represent merged vowels\n",
    "\n",
    "#and to get the entropy\n",
    "totalfreq = sum(merged.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in merged:\n",
    "    probabilities[key] = merged[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_merged = sum(surprisals.values())\n",
    "entropy_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004700602659523387"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_contr = (entropy_total - entropy_merged)/ entropy_total\n",
    "vowel_contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.980268014362102"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i I merger\n",
    "vowelstomerge = {'i', 'I'}\n",
    "vowelstomerge_dict = { key:value for key,value in result.items() if key in vowelstomerge}\n",
    "vowelstomerge_freq = sum(vowelstomerge_dict.values())\n",
    "nonmerged_dict = { key:value for key,value in result.items() if not key in vowelstomerge}\n",
    "merged = {**nonmerged_dict, **{'<':vowelstomerge_freq}} #using < to represent merged vowels\n",
    "\n",
    "#and to get the entropy\n",
    "totalfreq = sum(merged.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in merged:\n",
    "    probabilities[key] = merged[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_merged = sum(surprisals.values())\n",
    "entropy_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0151949269560139"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_contr = (entropy_total - entropy_merged)/ entropy_total\n",
    "vowel_contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.036590631204497"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# u U merger\n",
    "vowelstomerge = {'u', 'U'}\n",
    "vowelstomerge_dict = { key:value for key,value in result.items() if key in vowelstomerge}\n",
    "vowelstomerge_freq = sum(vowelstomerge_dict.values())\n",
    "nonmerged_dict = { key:value for key,value in result.items() if not key in vowelstomerge}\n",
    "merged = {**nonmerged_dict, **{'<':vowelstomerge_freq}} #using < to represent merged vowels\n",
    "\n",
    "#and to get the entropy\n",
    "totalfreq = sum(merged.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in merged:\n",
    "    probabilities[key] = merged[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_merged = sum(surprisals.values())\n",
    "entropy_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004057614941168968"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_contr = (entropy_total - entropy_merged)/ entropy_total\n",
    "vowel_contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.032814304689462"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# U V merger\n",
    "vowelstomerge = {'U', 'V'}\n",
    "vowelstomerge_dict = { key:value for key,value in result.items() if key in vowelstomerge}\n",
    "vowelstomerge_freq = sum(vowelstomerge_dict.values())\n",
    "nonmerged_dict = { key:value for key,value in result.items() if not key in vowelstomerge}\n",
    "merged = {**nonmerged_dict, **{'<':vowelstomerge_freq}} #using < to represent merged vowels\n",
    "\n",
    "#and to get the entropy\n",
    "totalfreq = sum(merged.values())\n",
    "\n",
    "probabilities = {}\n",
    "for key in merged:\n",
    "    probabilities[key] = merged[key]/totalfreq\n",
    "    \n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_merged = sum(surprisals.values())\n",
    "entropy_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004804350959943877"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_contr = (entropy_total - entropy_merged)/ entropy_total\n",
    "vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all words and frequencies\n",
    "word = []\n",
    "for row in r1:\n",
    "    word.append(row[4])\n",
    "    \n",
    "freq = []\n",
    "for row in r1:\n",
    "    freq.append(float(row[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are words that are already homophones in the corpus. \n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in word:\n",
    "    if word.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(word)) if word[i] == h ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(word)) if word[i] == h] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "word_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(word_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in word_dict:\n",
    "    probabilities[key] = word_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_words_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.690740841402093"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_words_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we want to see the vowel contribution at the word level.\n",
    "#First, replace all vowels with V.\n",
    "replace_dict = {'i':'V', 'I':'V', 'e':'V', 'E':'V', '@':'V', 'u':'V', 'U':'V', 'o':'V', 'c':'V', 'a':'V', 'R':'V'}\n",
    "vowelless = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function I found from https://codereview.stackexchange.com/questions/97318/string-replacement-using-dictionaries\n",
    "def keymap_replace(\n",
    "        string: str, \n",
    "        mappings: dict,\n",
    "        lower_keys=False,\n",
    "        lower_values=False,\n",
    "        lower_string=False,\n",
    "    ) -> str:\n",
    "    \"\"\"Replace parts of a string based on a dictionary.\n",
    "\n",
    "    This function takes a string a dictionary of\n",
    "    replacement mappings. For example, if I supplied\n",
    "    the string \"Hello world.\", and the mappings \n",
    "    {\"H\": \"J\", \".\": \"!\"}, it would return \"Jello world!\".\n",
    "\n",
    "    Keyword arguments:\n",
    "    string       -- The string to replace characters in.\n",
    "    mappings     -- A dictionary of replacement mappings.\n",
    "    lower_keys   -- Whether or not to lower the keys in mappings.\n",
    "    lower_values -- Whether or not to lower the values in mappings.\n",
    "    lower_string -- Whether or not to lower the input string.\n",
    "    \"\"\"\n",
    "    replaced_string = string.lower() if lower_string else string\n",
    "    for character, replacement in mappings.items():\n",
    "        replaced_string = replaced_string.replace(\n",
    "            character.lower() if lower_keys else character,\n",
    "            replacement.lower() if lower_values else replacement\n",
    "        )\n",
    "    return replaced_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_dict:\n",
    "    vowelless.append(keymap_replace(key, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same thing as above where the frequencies of homophones are added together\n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in vowelless:\n",
    "    if vowelless.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put frequencies in a list\n",
    "freq = list(word_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)\n",
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(vowelless)) if vowelless[i] == h ])\n",
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))\n",
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(vowelless)) if vowelless[i] == h] )\n",
    "\n",
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])\n",
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))\n",
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "vowelless_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowelless_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowelless_dict:\n",
    "    probabilities[key] = vowelless_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowelless_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.313873598607595"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowelless_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04336422517619309"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vowel_contr = (entropy_words_token - entropy_vowelless_token)/ entropy_words_token\n",
    "word_vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now some more fine-grained contrasts\n",
    "## front vowels all merged and back vowels all merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#First, replace all front vowels with 'i' and all back vowels with 'u'\n",
    "replace_dict = {'I':'i', 'e':'i', 'E':'i', '@':'i', 'R':'i', 'U':'u', 'o':'u', 'c':'u', 'a':'u', 'V':'u'}\n",
    "vowelless = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function I found from https://codereview.stackexchange.com/questions/97318/string-replacement-using-dictionaries\n",
    "def keymap_replace(\n",
    "        string: str, \n",
    "        mappings: dict,\n",
    "        lower_keys=False,\n",
    "        lower_values=False,\n",
    "        lower_string=False,\n",
    "    ) -> str:\n",
    "    \"\"\"Replace parts of a string based on a dictionary.\n",
    "\n",
    "    This function takes a string a dictionary of\n",
    "    replacement mappings. For example, if I supplied\n",
    "    the string \"Hello world.\", and the mappings \n",
    "    {\"H\": \"J\", \".\": \"!\"}, it would return \"Jello world!\".\n",
    "\n",
    "    Keyword arguments:\n",
    "    string       -- The string to replace characters in.\n",
    "    mappings     -- A dictionary of replacement mappings.\n",
    "    lower_keys   -- Whether or not to lower the keys in mappings.\n",
    "    lower_values -- Whether or not to lower the values in mappings.\n",
    "    lower_string -- Whether or not to lower the input string.\n",
    "    \"\"\"\n",
    "    replaced_string = string.lower() if lower_string else string\n",
    "    for character, replacement in mappings.items():\n",
    "        replaced_string = replaced_string.replace(\n",
    "            character.lower() if lower_keys else character,\n",
    "            replacement.lower() if lower_values else replacement\n",
    "        )\n",
    "    return replaced_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_dict:\n",
    "    vowelless.append(keymap_replace(key, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same thing as above where the frequencies of homophones are added together\n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in vowelless:\n",
    "    if vowelless.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put frequencies in a list\n",
    "freq = list(word_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)\n",
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(vowelless)) if vowelless[i] == h ])\n",
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))\n",
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(vowelless)) if vowelless[i] == h] )\n",
    "\n",
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])\n",
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))\n",
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "vowelless_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowelless_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowelless_dict:\n",
    "    probabilities[key] = vowelless_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowelless_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.466481589956453"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowelless_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025804388318344935"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vowel_contr = (entropy_words_token - entropy_vowelless_token)/ entropy_words_token\n",
    "word_vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and now high vs low vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all high vowels with 'i' and all low vowels with 'E'\n",
    "replace_dict = {'e': 'i', 'I': 'i', 'u': 'i', 'U': 'i', 'o': 'i', '@': 'E', 'a': 'E', 'c': 'E', 'R': 'E', 'V': 'E'}\n",
    "vowelless = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function I found from https://codereview.stackexchange.com/questions/97318/string-replacement-using-dictionaries\n",
    "def keymap_replace(\n",
    "        string: str, \n",
    "        mappings: dict,\n",
    "        lower_keys=False,\n",
    "        lower_values=False,\n",
    "        lower_string=False,\n",
    "    ) -> str:\n",
    "    \"\"\"Replace parts of a string based on a dictionary.\n",
    "\n",
    "    This function takes a string a dictionary of\n",
    "    replacement mappings. For example, if I supplied\n",
    "    the string \"Hello world.\", and the mappings \n",
    "    {\"H\": \"J\", \".\": \"!\"}, it would return \"Jello world!\".\n",
    "\n",
    "    Keyword arguments:\n",
    "    string       -- The string to replace characters in.\n",
    "    mappings     -- A dictionary of replacement mappings.\n",
    "    lower_keys   -- Whether or not to lower the keys in mappings.\n",
    "    lower_values -- Whether or not to lower the values in mappings.\n",
    "    lower_string -- Whether or not to lower the input string.\n",
    "    \"\"\"\n",
    "    replaced_string = string.lower() if lower_string else string\n",
    "    for character, replacement in mappings.items():\n",
    "        replaced_string = replaced_string.replace(\n",
    "            character.lower() if lower_keys else character,\n",
    "            replacement.lower() if lower_values else replacement\n",
    "        )\n",
    "    return replaced_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_dict:\n",
    "    vowelless.append(keymap_replace(key, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same thing as above where the frequencies of homophones are added together\n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in vowelless:\n",
    "    if vowelless.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put frequencies in a list\n",
    "freq = list(word_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)\n",
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(vowelless)) if vowelless[i] == h ])\n",
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))\n",
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(vowelless)) if vowelless[i] == h] )\n",
    "\n",
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])\n",
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))\n",
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "vowelless_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowelless_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowelless_dict:\n",
    "    probabilities[key] = vowelless_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowelless_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.512109186458147"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowelless_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02055424942519935"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vowel_contr = (entropy_words_token - entropy_vowelless_token)/ entropy_words_token\n",
    "word_vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and tense vs lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all tense vowels with 'i' and all lax vowels with 'I'\n",
    "replace_dict = {'e':'i', 'u':'i', 'a':'i', 'o':'i', 'c':'i', 'E':'I', 'U':'I', 'V':'I', '@':'I', 'R':'I' }\n",
    "vowelless = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function I found from https://codereview.stackexchange.com/questions/97318/string-replacement-using-dictionaries\n",
    "def keymap_replace(\n",
    "        string: str, \n",
    "        mappings: dict,\n",
    "        lower_keys=False,\n",
    "        lower_values=False,\n",
    "        lower_string=False,\n",
    "    ) -> str:\n",
    "    \"\"\"Replace parts of a string based on a dictionary.\n",
    "\n",
    "    This function takes a string a dictionary of\n",
    "    replacement mappings. For example, if I supplied\n",
    "    the string \"Hello world.\", and the mappings \n",
    "    {\"H\": \"J\", \".\": \"!\"}, it would return \"Jello world!\".\n",
    "\n",
    "    Keyword arguments:\n",
    "    string       -- The string to replace characters in.\n",
    "    mappings     -- A dictionary of replacement mappings.\n",
    "    lower_keys   -- Whether or not to lower the keys in mappings.\n",
    "    lower_values -- Whether or not to lower the values in mappings.\n",
    "    lower_string -- Whether or not to lower the input string.\n",
    "    \"\"\"\n",
    "    replaced_string = string.lower() if lower_string else string\n",
    "    for character, replacement in mappings.items():\n",
    "        replaced_string = replaced_string.replace(\n",
    "            character.lower() if lower_keys else character,\n",
    "            replacement.lower() if lower_values else replacement\n",
    "        )\n",
    "    return replaced_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_dict:\n",
    "    vowelless.append(keymap_replace(key, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same thing as above where the frequencies of homophones are added together\n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in vowelless:\n",
    "    if vowelless.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put frequencies in a list\n",
    "freq = list(word_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)\n",
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(vowelless)) if vowelless[i] == h ])\n",
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))\n",
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(vowelless)) if vowelless[i] == h] )\n",
    "\n",
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])\n",
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))\n",
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "vowelless_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowelless_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowelless_dict:\n",
    "    probabilities[key] = vowelless_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowelless_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.481174634919173"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowelless_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024113733260179755"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vowel_contr = (entropy_words_token - entropy_vowelless_token)/ entropy_words_token\n",
    "word_vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a c merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'c' with 'a'\n",
    "replace_dict = {'c': 'a'}\n",
    "vowelless = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_dict:\n",
    "    vowelless.append(keymap_replace(key, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same thing as above where the frequencies of homophones are added together\n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in vowelless:\n",
    "    if vowelless.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put frequencies in a list\n",
    "freq = list(word_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)\n",
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(vowelless)) if vowelless[i] == h ])\n",
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))\n",
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(vowelless)) if vowelless[i] == h] )\n",
    "\n",
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])\n",
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))\n",
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "vowelless_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowelless_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowelless_dict:\n",
    "    probabilities[key] = vowelless_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowelless_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.690078308858006"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowelless_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.623429994954556e-05"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vowel_contr = (entropy_words_token - entropy_vowelless_token)/ entropy_words_token\n",
    "word_vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i I merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'I' with 'i'\n",
    "replace_dict = {'I': 'i'}\n",
    "vowelless = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_dict:\n",
    "    vowelless.append(keymap_replace(key, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same thing as above where the frequencies of homophones are added together\n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in vowelless:\n",
    "    if vowelless.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put frequencies in a list\n",
    "freq = list(word_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)\n",
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(vowelless)) if vowelless[i] == h ])\n",
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))\n",
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(vowelless)) if vowelless[i] == h] )\n",
    "\n",
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])\n",
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))\n",
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "vowelless_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowelless_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowelless_dict:\n",
    "    probabilities[key] = vowelless_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowelless_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.683668374498042"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowelless_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008137933270726189"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vowel_contr = (entropy_words_token - entropy_vowelless_token)/ entropy_words_token\n",
    "word_vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## u U merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'U' with 'u'\n",
    "replace_dict = {'U': 'u'}\n",
    "vowelless = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_dict:\n",
    "    vowelless.append(keymap_replace(key, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same thing as above where the frequencies of homophones are added together\n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in vowelless:\n",
    "    if vowelless.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put frequencies in a list\n",
    "freq = list(word_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)\n",
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(vowelless)) if vowelless[i] == h ])\n",
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))\n",
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(vowelless)) if vowelless[i] == h] )\n",
    "\n",
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])\n",
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))\n",
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "vowelless_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowelless_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowelless_dict:\n",
    "    probabilities[key] = vowelless_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowelless_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.69023087944811"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowelless_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.867876666542823e-05"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vowel_contr = (entropy_words_token - entropy_vowelless_token)/ entropy_words_token\n",
    "word_vowel_contr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U V merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'V' with 'U'\n",
    "replace_dict = {'V': 'U'}\n",
    "vowelless = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in word_dict:\n",
    "    vowelless.append(keymap_replace(key, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do the same thing as above where the frequencies of homophones are added together\n",
    "homophones = []\n",
    "nonhomophones = []\n",
    "for w in vowelless:\n",
    "    if vowelless.count(w) > 1:\n",
    "        homophones.append(w)\n",
    "    else:\n",
    "        nonhomophones.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put frequencies in a list\n",
    "freq = list(word_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique homophones\n",
    "homophones = set(homophones)\n",
    "#get the indices for all the homophones\n",
    "indexPosList = []\n",
    "for h in homophones:\n",
    "    indexPosList.append([ i for i in range(len(vowelless)) if vowelless[i] == h ])\n",
    "#get the frequencies at those indices\n",
    "hfreq = []\n",
    "localfreq = []\n",
    "for j in range(len(indexPosList)):\n",
    "    for i in range(len(indexPosList[j])):\n",
    "        localfreq.append(freq[indexPosList[j][i]])\n",
    "    hfreq.append(np.array(localfreq))\n",
    "    localfreq = []\n",
    "#sum the frequencies for each homophone together\n",
    "hfreqsum = []\n",
    "for row in hfreq:\n",
    "    hfreqsum.append(np.sum(row, 0))\n",
    "#make a dictionary of homophones, summed frequencies \n",
    "hdict = dict(zip(homophones, hfreqsum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of all words that are not homophones with their frequencies\n",
    "#get the indices of all the nonhomophones in the word list\n",
    "indexPosList2 = []\n",
    "for h in nonhomophones:\n",
    "    indexPosList2.append([ i for i in range(len(vowelless)) if vowelless[i] == h] )\n",
    "\n",
    "#get the frequencies at those indices\n",
    "nhfreq = []\n",
    "for row in indexPosList2:\n",
    "    nhfreq.append(freq[row[0]])\n",
    "#make a dictionary of nonhomophones and frequencies\n",
    "nhdict = dict(zip(nonhomophones, nhfreq))\n",
    "#dictionary of all words, where each unique phonemic representation appears once \n",
    "#with the frequency of all homophones summed for that representation\n",
    "vowelless_dict = {**hdict, **nhdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy of system at the word level (token freq)\n",
    "\n",
    "#first get total frequency so we can get the probability\n",
    "totalfreq = sum(vowelless_dict.values())\n",
    "\n",
    "#now divide the frequency of each word by the total frequency to get the probability\n",
    "probabilities = {}\n",
    "for key in vowelless_dict:\n",
    "    probabilities[key] = vowelless_dict[key]/totalfreq\n",
    "    \n",
    "#now get the surprisal for each vowel times the probability for each vowel\n",
    "surprisals = {}\n",
    "for key in probabilities:\n",
    "    surprisals[key] = probabilities[key]*(math.log2(1/probabilities[key]))\n",
    "\n",
    "#now add all of those together to get the entropy\n",
    "entropy_vowelless_token = sum(surprisals.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.689595295704388"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_vowelless_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013181220319534486"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vowel_contr = (entropy_words_token - entropy_vowelless_token)/ entropy_words_token\n",
    "word_vowel_contr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
